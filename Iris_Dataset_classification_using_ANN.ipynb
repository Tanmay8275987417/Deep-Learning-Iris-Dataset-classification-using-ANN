{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Dataset classification using ANN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5JDjFSnlR6/hQKM/gj/jC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanmay8275987417/Deep-Learning-Iris-Dataset-classification-using-ANN/blob/main/Iris_Dataset_classification_using_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqFi-dyqM164"
      },
      "source": [
        "# **Classification of IRIS Flower using Artifical Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYZ8EpoqgAna"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "import numpy as np    # For Operations\n",
        "import pandas as pd   # For Data Import\n",
        "import keras\n",
        "from keras.models import Sequential   # Imported Sequencial Model\n",
        "from keras.layers import Dense    # For Layers\n",
        "from keras.optimizers import Adam   # For Optimizers\n",
        "import pydot\n",
        "import graphviz\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3X1gwSaMuhk"
      },
      "source": [
        "# Information about Data\n",
        "\n",
        "The Iris dataset has 150 observations or Rows and 5 atttibutes or Columns of Iris Flowers.\n",
        "\n",
        "First four columns are - **Sepal Length, Sepal Width , Petal Length, Petal Width**, all are in cm.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The Last column is containing the Classes - **['setosa' 'versicolor' 'virginica']**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Classes are - [ 0 , 1 , 2 ] instead of ['setosa' 'versicolor' 'virginica'].**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "emJrmyH2fHeR",
        "outputId": "96e8cc9c-5d13-4d69-ca5c-cc179453bcac"
      },
      "source": [
        "# Import dataset on Google Colab\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['iris.data']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8912749c-367d-4fe7-91d7-bf4967725ef8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8912749c-367d-4fe7-91d7-bf4967725ef8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iris.data to iris.data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDhBJgB8ff7Q",
        "outputId": "a511ced5-efd4-4733-d5fe-0834d13dd247"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     5.1  3.5  1.4  0.2     Iris-setosa\n",
            "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
            "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
            "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
            "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
            "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
            "..   ...  ...  ...  ...             ...\n",
            "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
            "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
            "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
            "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
            "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
            "\n",
            "[149 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wriVl13LwR91"
      },
      "source": [
        "## Data Preprossing\n",
        "\n",
        "In data preprossing, I have detected the missing values in data set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Atb3bCV_s7ay",
        "outputId": "35ac46a9-10d9-4692-cffd-76ea5711b5ec"
      },
      "source": [
        "pd.isna(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5.1</th>\n",
              "      <th>3.5</th>\n",
              "      <th>1.4</th>\n",
              "      <th>0.2</th>\n",
              "      <th>Iris-setosa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       5.1    3.5    1.4    0.2  Iris-setosa\n",
              "0    False  False  False  False        False\n",
              "1    False  False  False  False        False\n",
              "2    False  False  False  False        False\n",
              "3    False  False  False  False        False\n",
              "4    False  False  False  False        False\n",
              "..     ...    ...    ...    ...          ...\n",
              "144  False  False  False  False        False\n",
              "145  False  False  False  False        False\n",
              "146  False  False  False  False        False\n",
              "147  False  False  False  False        False\n",
              "148  False  False  False  False        False\n",
              "\n",
              "[149 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Z0d6C3I1v3dK",
        "outputId": "a7766270-531f-4957-9144-f1635e68eef9"
      },
      "source": [
        "sns.heatmap(data.isnull(), yticklabels=False) #cbar=False,cmap='viridis')  # Heatmap is showing us that there is no missing values in the dataset  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f590aebacd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4acf6TocHo0Y"
      },
      "source": [
        "It seems that there are no missing data, hence the data is ready to proccede further for selecting the independent and Dependent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFORWwqEgbs7"
      },
      "source": [
        "X = data.iloc[:,0:4].values # Selecting Features\n",
        "y = data.iloc[:,4].values   # Target Variable\n",
        "\n",
        "# Transforming the Target varible by using Label Encoder \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)\n",
        "Y = pd.get_dummies(y1).values\n",
        "\n",
        "# Spliting the dataset 70% Training data and 30% Testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8lLmfi8jI1r",
        "outputId": "2a26b560-1e59-4b22-ae36-1f4bfedced0c"
      },
      "source": [
        "y1    # Encoded y1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2KSIpIgK0DZ"
      },
      "source": [
        "## Implementing the Artificial Neural Network for classification of IRIS Flower\n",
        "\n",
        "Here I have created the ANN model to classify th IRIS flower in encoded form **0 - Setosa, 1- Versicolor and 2 -Virginica**.\n",
        "\n",
        "By using 2 hidden layers with **relu activation function**, followed by **Softmax activation function** in the Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLAf3iuHkKvD"
      },
      "source": [
        "# Building the Model\n",
        "\n",
        "model = Sequential(name=\"my_sequential\")\n",
        "\n",
        "model.add(Dense(50,input_shape=(4,), activation='relu', name=\"layer1\"))   # Input(4) Layer and First hidden layer with 10 Nurons using relu activation function\n",
        "\n",
        "model.add(Dense(50, activation='relu',name=\"layer2\")) # Second hidden layer with 50 Nurons using relu activation function\n",
        "\n",
        "model.add(Dense(3, activation='softmax', name=\"layer3\")) # Output(3) Layer with Softmax Activation function\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ2KgKZIXZhP",
        "outputId": "01e78e55-2137-4357-bd4f-95692de393d3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 50)                250       \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 2,953\n",
            "Trainable params: 2,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RzHru9vlaiK"
      },
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])    #"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrvgRZMimA0P",
        "outputId": "376a0650-31a1-4993-c9b0-4d76be229b45"
      },
      "source": [
        "# Fit the Model\n",
        "model.fit(X_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 1.4413 - accuracy: 0.3286\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1008 - accuracy: 0.1582\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9748 - accuracy: 0.4534\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6480\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7873 - accuracy: 0.6486\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.7269\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6901\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.8295\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.6790\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7689\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.9595\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8434\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8841\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.9801\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.9008\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8961\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.9325\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.9811\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.9453\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.9400\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.9304\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.9419\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9602\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9781\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9408\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9404\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9873\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9687\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9648\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9827\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9083\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9706\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9232\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9585\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9785\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9804\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9477\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9617\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9453\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9589\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9480\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9827\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9493\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9753\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9497\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9709\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9589\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9916\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9476\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9798\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9493\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9735\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9783\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9636\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9889\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9762\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9662\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9745\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9773\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9787\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9584\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9662\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9404\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9636\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9849\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9673\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9737\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9446\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9762\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9841\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9484\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9568\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9196\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9795\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9763\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9491\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9509\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9628\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9880\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9880\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9686\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9815\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9944\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9844\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9823\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9858\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9795\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9696\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9753\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9888\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9519\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9852\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9474\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9785\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9742\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9445\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9688\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9900\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58fbe0e150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Lgz2Dnmeaf",
        "outputId": "8a6261c4-534c-46ad-95c0-ebbeebfc909e"
      },
      "source": [
        "# Predicting the results\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_pred_class"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 1, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_nwN7bdoICc",
        "outputId": "b53edf6b-c82f-4b45-d68a-b755fe3a0e61"
      },
      "source": [
        "# Confusion matrix for finding out the accuracy, f1-score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "print(confusion_matrix(y_test_class,y_pred_class))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.94      1.00      0.97        16\n",
            "           2       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "[[16  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  1 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pGIx3lUovGi",
        "outputId": "00a8d172-e6d1-4930-bf27-4ffd260df2a8"
      },
      "source": [
        "(16+16+12)/45\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmtAdXspC5q",
        "outputId": "80172223-521f-438b-dcb7-d8c894de10e2"
      },
      "source": [
        "# Evaluate the Model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05739866942167282, 0.9777777791023254]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hZ72Vqfpv_-",
        "outputId": "329ac9fb-0f7e-4940-da76-3ad76de1715d"
      },
      "source": [
        "# Predict for the first 10 Observations\n",
        "pred=model.predict(X_test[:10])\n",
        "print(pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.6210704e-06 5.4175343e-02 9.4581699e-01]\n",
            " [6.8392255e-05 2.5788179e-01 7.4204981e-01]\n",
            " [1.9539075e-03 9.8843026e-01 9.6158609e-03]\n",
            " [2.0074539e-03 9.9678111e-01 1.2113876e-03]\n",
            " [9.9703920e-01 2.9608817e-03 2.6839201e-08]\n",
            " [4.4123208e-08 2.0050635e-03 9.9799490e-01]\n",
            " [1.4532479e-05 8.4927283e-02 9.1505814e-01]\n",
            " [1.2399117e-03 9.9250424e-01 6.2557994e-03]\n",
            " [1.7889100e-05 8.2449295e-02 9.1753280e-01]\n",
            " [1.2203994e-03 9.8887676e-01 9.9027818e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCmN5aDwqJgi",
        "outputId": "d62d02e4-683c-40dd-acc1-7118adb6be9c"
      },
      "source": [
        "# Comparing the predicted class with the actual Class\n",
        "p=np.argmax(pred, axis=1)\n",
        "print(p)\n",
        "print(y_pred_class[:10])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 1 1 0 2 2 1 2 1]\n",
            "[2 2 1 1 0 2 2 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJlxZtH0QbY3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}