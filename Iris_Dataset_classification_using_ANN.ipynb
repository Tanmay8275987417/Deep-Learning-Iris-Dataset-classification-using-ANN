{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Dataset classification using ANN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOT2zRIeIdfPGBNfEj1eUIc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanmay8275987417/Deep-Learning-Iris-Dataset-classification-using-ANN/blob/main/Iris_Dataset_classification_using_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqFi-dyqM164"
      },
      "source": [
        "# **Classification of IRIS Flower using Artifical Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYZ8EpoqgAna"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "import numpy as np    # For Operations\n",
        "import pandas as pd   # For Data Import\n",
        "import keras\n",
        "from keras.models import Sequential   # Imported Sequencial Model\n",
        "from keras.layers import Dense    # For Layers\n",
        "from keras.optimizers import Adam   # For Optimizers\n",
        "import pydot\n",
        "import graphviz\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3X1gwSaMuhk"
      },
      "source": [
        "# Information about Data\n",
        "\n",
        "The Iris dataset has 150 observations or Rows and 5 atttibutes or Columns of Iris Flowers.\n",
        "\n",
        "First four columns are - **Sepal Length, Sepal Width , Petal Length, Petal Width**, all are in cm.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The Last column is containing the Classes - **['setosa' 'versicolor' 'virginica']**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Classes are - [ 0 , 1 , 2 ] instead of ['setosa' 'versicolor' 'virginica'].**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "emJrmyH2fHeR",
        "outputId": "b0ed1f6e-f19e-4db8-b477-c31707b4937b"
      },
      "source": [
        "# Import dataset on Google Colab\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['iris.data']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5df37e8c-77eb-44dc-9794-24a56d6f7797\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5df37e8c-77eb-44dc-9794-24a56d6f7797\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iris.data to iris (1).data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDhBJgB8ff7Q",
        "outputId": "0f735823-d67f-4c6a-bebb-b29adc3b9129"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     5.1  3.5  1.4  0.2     Iris-setosa\n",
            "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
            "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
            "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
            "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
            "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
            "..   ...  ...  ...  ...             ...\n",
            "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
            "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
            "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
            "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
            "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
            "\n",
            "[149 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wriVl13LwR91"
      },
      "source": [
        "## Data Preprossing\n",
        "\n",
        "In data preprossing, I have detected the missing values in data set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Atb3bCV_s7ay",
        "outputId": "7218729b-8411-463a-ecf9-c8d2ad3aa261"
      },
      "source": [
        "pd.isna(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5.1</th>\n",
              "      <th>3.5</th>\n",
              "      <th>1.4</th>\n",
              "      <th>0.2</th>\n",
              "      <th>Iris-setosa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       5.1    3.5    1.4    0.2  Iris-setosa\n",
              "0    False  False  False  False        False\n",
              "1    False  False  False  False        False\n",
              "2    False  False  False  False        False\n",
              "3    False  False  False  False        False\n",
              "4    False  False  False  False        False\n",
              "..     ...    ...    ...    ...          ...\n",
              "144  False  False  False  False        False\n",
              "145  False  False  False  False        False\n",
              "146  False  False  False  False        False\n",
              "147  False  False  False  False        False\n",
              "148  False  False  False  False        False\n",
              "\n",
              "[149 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Z0d6C3I1v3dK",
        "outputId": "bc9a1ea7-49d3-4d71-92a9-e31e37a67953"
      },
      "source": [
        "sns.heatmap(data.isnull(), yticklabels=False) #cbar=False,cmap='viridis')  # Heatmap is showing us that there is no missing values in the dataset  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0c57f532d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4acf6TocHo0Y"
      },
      "source": [
        "It seems that there are no missing data, hence the data is ready to proccede further for selecting the independent and Dependent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFORWwqEgbs7"
      },
      "source": [
        "X = data.iloc[:,0:4].values # Selecting Features\n",
        "y = data.iloc[:,4].values   # Target Variable\n",
        "\n",
        "# Transforming the Target varible by using Label Encoder \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)\n",
        "Y = pd.get_dummies(y1).values\n",
        "\n",
        "# Spliting the dataset 70% Training data and 30% Testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8lLmfi8jI1r",
        "outputId": "e869eadc-27e2-42dd-add6-d6dfc27b134c"
      },
      "source": [
        "y1    # Encoded y1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2KSIpIgK0DZ"
      },
      "source": [
        "## Implementing the Artificial Neural Network for classification of IRIS Flower\n",
        "\n",
        "Here I have created the ANN model to classify th IRIS flower in encoded form **0 - Setosa, 1- Versicolor and 2 -Virginica**.\n",
        "\n",
        "By using 2 hidden layers with **relu activation function**, followed by **Softmax activation function** in the Output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLAf3iuHkKvD"
      },
      "source": [
        "# Building the Model\n",
        "\n",
        "model = Sequential(name=\"my_sequential\")\n",
        "\n",
        "model.add(Dense(10,input_shape=(4,), activation='relu', name=\"layer1\"))   # Input(4) Layer and First hidden layer with 10 Nurons using relu activation function\n",
        "\n",
        "model.add(Dense(50, activation='relu',name=\"layer2\")) # Second hidden layer with 50 Nurons using relu activation function\n",
        "\n",
        "model.add(Dense(3, activation='softmax', name=\"layer3\")) # Output(3) Layer with Softmax Activation function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ2KgKZIXZhP",
        "outputId": "0ab818f4-4295-42d6-a420-337ad8808eee"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 50)                550       \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 753\n",
            "Trainable params: 753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RzHru9vlaiK"
      },
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])    #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrvgRZMimA0P",
        "outputId": "93bce86c-905d-48d0-a26d-264d42684da6"
      },
      "source": [
        "# Fit the Model\n",
        "model.fit(X_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 2ms/step - loss: 1.0098 - accuracy: 0.3040\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.5498\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8300 - accuracy: 0.6802\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7828 - accuracy: 0.6615\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.6475\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6642\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6539\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6019\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7085\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7231\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8387\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.8628\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8834\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8664\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8724\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.9087\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.9193\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.9586\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.9646\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.9301\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.9076\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.9630\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.9429\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.9229\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.9242\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.9509\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.9508\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9477\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.9558\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.9727\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.9767\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9432\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9325\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.9504\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9687\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9661\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9689\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9782\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.9248\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9617\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9527\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9508\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9808\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9258\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9717\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9709\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9757\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9460\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9526\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9437\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9825\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9059\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9370\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9475\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9562\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9563\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9157\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9539\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9394\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9596\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9381\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9654\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9127\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9834\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9810\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.8921\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9691\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9351\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9800\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9739\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9514\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9844\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9305\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9400\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9585\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9539\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9766\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9614\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9779\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9188\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9372\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9660\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9147\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9707\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9425\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9571\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9510\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9470\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9894\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9685\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9743\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9879\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9130\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9675\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9647\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9756\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9669\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9721\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9643\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c5815aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Lgz2Dnmeaf",
        "outputId": "e3b79a9a-b7d7-4175-950e-c5e51399a020"
      },
      "source": [
        "# Predicting the results\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_pred_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 1, 0, 2, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_nwN7bdoICc",
        "outputId": "26cf8997-6813-4f47-b33c-a49f61f52531"
      },
      "source": [
        "# Confusion matrix for finding out the accuracy, f1-score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test_class,y_pred_class))\n",
        "print(confusion_matrix(y_test_class,y_pred_class))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.94      1.00      0.97        16\n",
            "           2       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n",
            "[[16  0  0]\n",
            " [ 0 16  0]\n",
            " [ 0  1 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pGIx3lUovGi",
        "outputId": "8181e043-a435-4c8c-e992-b4b14a632abf"
      },
      "source": [
        "(16+16+12)/45\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmtAdXspC5q",
        "outputId": "ee2b5ef6-0793-451e-ae10-4740413fa906"
      },
      "source": [
        "# Evaluate the Model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06792823225259781, 0.9777777791023254]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hZ72Vqfpv_-",
        "outputId": "2e72bd24-5b97-4551-84c5-4772d51e5318"
      },
      "source": [
        "# Predict for the first 10 Observations\n",
        "pred=model.predict(X_test[:10])\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.80300902e-05 1.09536454e-01 8.90365481e-01]\n",
            " [1.60209223e-04 3.68840903e-01 6.30998850e-01]\n",
            " [3.26175103e-03 9.38698828e-01 5.80394678e-02]\n",
            " [2.36917171e-03 9.87573028e-01 1.00578666e-02]\n",
            " [9.98321474e-01 1.67843804e-03 9.90994877e-08]\n",
            " [6.29503290e-07 4.71963873e-03 9.95279789e-01]\n",
            " [2.68389158e-05 1.13710366e-01 8.86262715e-01]\n",
            " [1.58759684e-03 9.79472518e-01 1.89398658e-02]\n",
            " [5.85500056e-05 6.59970865e-02 9.33944345e-01]\n",
            " [1.02149113e-03 9.81317341e-01 1.76610928e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCmN5aDwqJgi",
        "outputId": "80ec831c-b75a-4310-f155-e62885c82dd0"
      },
      "source": [
        "# Comparing the predicted class with the actual Class\n",
        "p=np.argmax(pred, axis=1)\n",
        "print(p)\n",
        "print(y_pred_class[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 1 1 0 2 2 1 2 1]\n",
            "[2 2 1 1 0 2 2 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJlxZtH0QbY3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}